{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, Dataset, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "\ttransforms.ToTensor(),\n",
    "\ttransforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# the dataset is 600 by 600\n",
    "dataset = datasets.ImageFolder('data', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PORTION = 0.8\n",
    "\n",
    "train_size = int(TRAIN_PORTION * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homebrew CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceClasifier(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(FaceClasifier, self).__init__()\n",
    "\t\tself.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1)\n",
    "\t\tself.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n",
    "\t\tself.pool = nn.MaxPool2d(3, 3)\n",
    "\t\tself.fc1 = nn.Linear(32 * 32 * 32, 128)\n",
    "\t\tself.fc2 = nn.Linear(128, 2)\n",
    "\t\tself.dropout = nn.Dropout(0.25)\n",
    "\t\tself.relu = nn.LeakyReLU()\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\t# x 3x600x600\n",
    "\t\tx = self.pool(self.relu(self.conv1(x)))\n",
    "\t\t# x 16x199x199\n",
    "\t\tx = self.pool(self.relu(self.conv2(x)))\n",
    "\t\t# x 32x32x32\n",
    "\t\tx = x.view(-1, 32 * 32 * 32)\n",
    "\t\tx = self.relu(self.fc1(x))\n",
    "\t\tx = self.fc2(x)\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FaceClasifier().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight              432\n",
      "conv1.bias                 16\n",
      "conv2.weight           12,800\n",
      "conv2.bias                 32\n",
      "fc1.weight          4,194,304\n",
      "fc1.bias                  128\n",
      "fc2.weight                256\n",
      "fc2.bias                    2\n",
      "-----------------------------\n",
      "Total parameters:   4,207,970\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "\t# print parameter name and size\n",
    "\tprint(f\"{name: <13} {param.numel(): >15,}\")\n",
    "print('-----------------------------')\n",
    "print(f'Total parameters: {sum(p.numel() for p in model.parameters()): >11,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f89431aa9bc4f6d82858c48aee8764c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/3:   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3a01e40b3a347a29c39c64978fd3a7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/3:   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc4e0f5c9b3d4beab48e2d61a680b734",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/3:   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "from collections import defaultdict\n",
    "\n",
    "train_losses = defaultdict(list)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\tnum_batches = len(train_loader)\n",
    "\tfor i, (inputs, label) in tqdm(enumerate(train_loader, 1), total=num_batches, desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n",
    "\t\tinputs = inputs.to(device)\n",
    "\t\tlabel = label.to(device)\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\toutputs = model(inputs)\n",
    "\t\tloss = criteria(outputs, label)\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\ttrain_losses[\"batch\"].append(i + num_batches * epoch)\n",
    "\t\ttrain_losses[\"loss\"].append(loss.item())\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 409 test images: 60.15%\n"
     ]
    }
   ],
   "source": [
    "# test accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "for inputs, label in test_loader:\n",
    "\tinputs = inputs.to(device)\n",
    "\tlabel = label.to(device)\n",
    "\toutputs = model(inputs)\n",
    "\t_, predicted = torch.max(outputs.data, 1)\n",
    "\ttotal += label.size(0)\n",
    "\tcorrect += (predicted == label).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the {total} test images: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1632 train images: 67.71%\n"
     ]
    }
   ],
   "source": [
    "# train accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "for inputs, label in train_loader:\n",
    "\tinputs = inputs.to(device)\n",
    "\tlabel = label.to(device)\n",
    "\toutputs = model(inputs)\n",
    "\t_, predicted = torch.max(outputs.data, 1)\n",
    "\ttotal += label.size(0)\n",
    "\tcorrect += (predicted == label).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the {total} train images: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying different non sequential models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NonSequentialFaceClassifieir(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(NonSequentialFaceClassifieir, self).__init__()\n",
    "\t\tself.start_conv = nn.Conv2d(3, 16, kernel_size=3, stride=1)\n",
    "\n",
    "\t\tself.left_conv1 = nn.Conv2d(16, 24, kernel_size=5, stride=1)\n",
    "\t\tself.left_conv2 = nn.Conv2d(24, 32, kernel_size=5, stride=1)\n",
    "\t\tself.left_conv3 = nn.Conv2d(32, 4, kernel_size=7, stride=1)\n",
    "\n",
    "\t\tself.right_conv1 = nn.Conv2d(16, 24, kernel_size=3, stride=1)\n",
    "\t\tself.right_conv2 = nn.Conv2d(24, 32, kernel_size=3, stride=1)\n",
    "\t\tself.right_conv3 = nn.Conv2d(32, 4, kernel_size=7, stride=1)\n",
    "\n",
    "\t\tself.left_fc = nn.Linear(4*20*20, 32)\n",
    "\t\tself.right_fc = nn.Linear(4*21*21, 32)\n",
    "\t\tself.join_fc = nn.Linear(64, 2)\n",
    "\t\t\n",
    "\t\tself.pool2 = nn.MaxPool2d(2, 2)\n",
    "\t\tself.pool3 = nn.MaxPool2d(3, 3)\n",
    "\t\t#self.dropout = nn.Dropout(0.25)\n",
    "\t\tself.relu = nn.LeakyReLU()\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\t# x 3x600x600\n",
    "\t\tx = self.pool2(self.relu(self.start_conv(x)))\n",
    "\t\t# x 16x299x299\n",
    "\n",
    "\t\tleft = self.pool2(self.relu(self.left_conv1(x)))\n",
    "\t\t# left 24x147x147\n",
    "\t\tleft = self.pool3(self.relu(self.left_conv2(left)))\n",
    "\t\t# left 32x47x47\n",
    "\t\tleft = self.pool2(self.relu(self.left_conv3(left)))\n",
    "\t\t# left 4x21x21\n",
    "\t\tleft = left.view(-1, 4*20*20)\n",
    "\t\tleft = self.relu(self.left_fc(left))\n",
    "\n",
    "\t\tright = self.pool2(self.relu(self.right_conv1(x)))\n",
    "\t\t# right 24x148x148\n",
    "\t\tright = self.pool3(self.relu(self.right_conv2(right)))\n",
    "\t\t# right 32x48x48\n",
    "\t\tright = self.pool2(self.relu(self.right_conv3(right)))\n",
    "\t\t# right 4x21x21\n",
    "\t\tright = right.view(-1, 4*21*21)\n",
    "\t\tright = self.relu(self.right_fc(right))\n",
    "\n",
    "\t\tx = torch.cat((left, right), dim=1)\n",
    "\t\tx = self.join_fc(x)\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NonSequentialFaceClassifieir().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_conv.weight              432\n",
      "start_conv.bias                 16\n",
      "left_conv1.weight            9,600\n",
      "left_conv1.bias                 24\n",
      "left_conv2.weight           19,200\n",
      "left_conv2.bias                 32\n",
      "left_conv3.weight            6,272\n",
      "left_conv3.bias                  4\n",
      "right_conv1.weight           3,456\n",
      "right_conv1.bias                24\n",
      "right_conv2.weight           6,912\n",
      "right_conv2.bias                32\n",
      "right_conv3.weight           6,272\n",
      "right_conv3.bias                 4\n",
      "left_fc.weight              51,200\n",
      "left_fc.bias                    32\n",
      "right_fc.weight             56,448\n",
      "right_fc.bias                   32\n",
      "join_fc.weight                 128\n",
      "join_fc.bias                     2\n",
      "-----------------------------------\n",
      "Total parameters:          160,122\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "\t# print parameter name and size\n",
    "\tprint(f\"{name: <18} {param.numel(): >15,}\")\n",
    "print('-----------------------------------')\n",
    "print(f'Total parameters: {sum(p.numel() for p in model.parameters()): >16,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4014f62267a49cdbeee59d8f151eada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/3:   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 1 loss: 0.708857536315918\n",
      "batch: 2 loss: 0.6983399391174316\n",
      "batch: 3 loss: 0.6713575720787048\n",
      "batch: 4 loss: 0.841963529586792\n",
      "batch: 5 loss: 0.733074963092804\n",
      "batch: 6 loss: 0.6964792609214783\n",
      "batch: 7 loss: 0.6984120011329651\n",
      "batch: 8 loss: 0.7125332355499268\n",
      "batch: 9 loss: 0.7032606601715088\n",
      "batch: 10 loss: 0.7037613987922668\n",
      "batch: 11 loss: 0.7031676769256592\n",
      "batch: 12 loss: 0.6948886513710022\n",
      "batch: 13 loss: 0.6926650404930115\n",
      "batch: 14 loss: 0.6957420706748962\n",
      "batch: 15 loss: 0.6950023770332336\n",
      "batch: 16 loss: 0.6971662044525146\n",
      "batch: 17 loss: 0.6922069191932678\n",
      "batch: 18 loss: 0.6917958855628967\n",
      "batch: 19 loss: 0.6907815933227539\n",
      "batch: 20 loss: 0.6924480199813843\n",
      "batch: 21 loss: 0.7008078098297119\n",
      "batch: 22 loss: 0.6918615698814392\n",
      "batch: 23 loss: 0.691635012626648\n",
      "batch: 24 loss: 0.6945517659187317\n",
      "batch: 25 loss: 0.6864508986473083\n",
      "batch: 26 loss: 0.7000986337661743\n",
      "Epoch [1/3], Loss: 0.7001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d30ca9045404c62ae2b4b92885ffe54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/3:   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 27 loss: 0.653517484664917\n",
      "batch: 28 loss: 0.6976638436317444\n",
      "batch: 29 loss: 0.7380903363227844\n",
      "batch: 30 loss: 0.6851528286933899\n",
      "batch: 31 loss: 0.6865273714065552\n",
      "batch: 32 loss: 0.6894882321357727\n",
      "batch: 33 loss: 0.6970022916793823\n",
      "batch: 34 loss: 0.688902735710144\n",
      "batch: 35 loss: 0.6942437291145325\n",
      "batch: 36 loss: 0.6881240606307983\n",
      "batch: 37 loss: 0.6868188977241516\n",
      "batch: 38 loss: 0.6982330083847046\n",
      "batch: 39 loss: 0.6890639066696167\n",
      "batch: 40 loss: 0.6864609122276306\n",
      "batch: 41 loss: 0.6847558617591858\n",
      "batch: 42 loss: 0.6871620416641235\n",
      "batch: 43 loss: 0.673317551612854\n",
      "batch: 44 loss: 0.6594820618629456\n",
      "batch: 45 loss: 0.697297215461731\n",
      "batch: 46 loss: 0.7147015333175659\n",
      "batch: 47 loss: 0.6770121455192566\n",
      "batch: 48 loss: 0.6740806102752686\n",
      "batch: 49 loss: 0.6753422617912292\n",
      "batch: 50 loss: 0.6952528953552246\n",
      "batch: 51 loss: 0.6787893176078796\n",
      "batch: 52 loss: 0.7029276490211487\n",
      "Epoch [2/3], Loss: 0.7029\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85757460259a4a58b50835035230c5c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/3:   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 53 loss: 0.691433846950531\n",
      "batch: 54 loss: 0.641864538192749\n",
      "batch: 55 loss: 0.649276077747345\n",
      "batch: 56 loss: 0.6657522320747375\n",
      "batch: 57 loss: 0.747175931930542\n",
      "batch: 58 loss: 0.6384537816047668\n",
      "batch: 59 loss: 0.6677986979484558\n",
      "batch: 60 loss: 0.6637804508209229\n",
      "batch: 61 loss: 0.6843648552894592\n",
      "batch: 62 loss: 0.6781657338142395\n",
      "batch: 63 loss: 0.6499625444412231\n",
      "batch: 64 loss: 0.6760348677635193\n",
      "batch: 65 loss: 0.6681972146034241\n",
      "batch: 66 loss: 0.6503133773803711\n",
      "batch: 67 loss: 0.6462848782539368\n",
      "batch: 68 loss: 0.6453086733818054\n",
      "batch: 69 loss: 0.6650817394256592\n",
      "batch: 70 loss: 0.7145400643348694\n",
      "batch: 71 loss: 0.6479955315589905\n",
      "batch: 72 loss: 0.5719088315963745\n",
      "batch: 73 loss: 0.7448041439056396\n",
      "batch: 74 loss: 0.6292271018028259\n",
      "batch: 75 loss: 0.7319128513336182\n",
      "batch: 76 loss: 0.7165075540542603\n",
      "batch: 77 loss: 0.7169836163520813\n",
      "batch: 78 loss: 0.7022318243980408\n",
      "Epoch [3/3], Loss: 0.7022\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "from collections import defaultdict\n",
    "history = defaultdict(list)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\tfor i, (train, label) in tqdm(enumerate(train_loader, 1), total=len(train_loader), desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n",
    "\t\ttrain = train.to(device)\n",
    "\t\tlabel = label.to(device)\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\toutputs = model(train)\n",
    "\t\tloss = criteria(outputs, label)\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\thistory[\"batch\"].append(i + len(train_loader) * epoch)\n",
    "\t\thistory[\"loss\"].append(loss.item())\n",
    "\t\tprint(\"batch:\", i + len(train_loader) * epoch, \"loss:\", loss.item())\n",
    "\tprint (f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1632 train images: 49.26%\n"
     ]
    }
   ],
   "source": [
    "# train accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "for inputs, label in train_loader:\n",
    "\tinputs = inputs.to(device)\n",
    "\tlabel = label.to(device)\n",
    "\toutputs = model(inputs)\n",
    "\t_, predicted = torch.max(outputs.data, 1)\n",
    "\ttotal += label.size(0)\n",
    "\tcorrect += (predicted == label).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the {total} train images: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 409 test images: 49.63%\n"
     ]
    }
   ],
   "source": [
    "# test accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "for inputs, label in test_loader:\n",
    "\tinputs = inputs.to(device)\n",
    "\tlabel = label.to(device)\n",
    "\toutputs = model(inputs)\n",
    "\t_, predicted = torch.max(outputs.data, 1)\n",
    "\ttotal += label.size(0)\n",
    "\tcorrect += (predicted == label).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the {total} test images: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history[\"batch\"], history[\"loss\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16 transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_preused_features = 24\n",
    "augment_factor = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = models.vgg16(weights='DEFAULT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AugmentDataset(Dataset):\n",
    "\tdef __init__(self, dataset, expansion):\n",
    "\t\tself.dataset = dataset\n",
    "\t\tself.expansion = expansion\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.dataset) * self.expansion\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\toriginal, label = self.dataset[idx % len(self.dataset)]\n",
    "\t\treturn original, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_prefix = vgg16.features[:num_preused_features]\n",
    "vgg16_prefix.to(device)\n",
    "\n",
    "class PrecomputeDataset(Dataset):\n",
    "\tdef __init__(self, dataset):\n",
    "\t\tself.dataset = dataset\n",
    "\t\tself.precomputed = {}\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.dataset)\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\tif idx not in self.precomputed:\n",
    "\t\t\toriginal, label = self.dataset[idx]\n",
    "\t\t\tprecomputed = vgg16_prefix(original.to(device)).detach().cpu()\n",
    "\t\t\tself.precomputed[idx] = (precomputed, label)\n",
    "\t\treturn self.precomputed[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "\ttransforms.Resize((224, 224)),\n",
    "\ttransforms.RandomRotation(30), \n",
    "\ttransforms.RandomHorizontalFlip(),\n",
    "\ttransforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n",
    "\ttransforms.ToTensor(),\n",
    "\ttransforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "\ttransforms.Resize((224, 224)),\n",
    "\ttransforms.ToTensor(),\n",
    "\ttransforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  \n",
    "])\n",
    "\n",
    "\n",
    "train_dataset = datasets.ImageFolder('data', transform=transform_train)\n",
    "test_dataset = datasets.ImageFolder('data', transform=transform_test)\n",
    "\n",
    "indices = torch.randperm(len(train_dataset))\n",
    "train_size = int(TRAIN_PORTION * len(train_dataset))\n",
    "\n",
    "train_dataset = torch.utils.data.Subset(train_dataset, indices[:train_size])\n",
    "test_dataset = torch.utils.data.Subset(test_dataset, indices[train_size:])\n",
    "\n",
    "train_dataset = AugmentDataset(train_dataset, augment_factor)\n",
    "\n",
    "train_dataset = PrecomputeDataset(train_dataset)\n",
    "test_dataset = PrecomputeDataset(test_dataset)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrecomputedClassifier(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(PrecomputedClassifier, self).__init__()\n",
    "\t\tself.seq = nn.Sequential(\n",
    "\t\t\tnn.Conv2d(512, 256, kernel_size=3),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Conv2d(256, 128, kernel_size=3),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Flatten(start_dim=-3), # flatten all but batch dimension\n",
    "\t\t\tnn.Linear(12800, 4096),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.BatchNorm1d(4096),\n",
    "\t\t\tnn.Linear(4096, 2048),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.BatchNorm1d(2048),\n",
    "\t\t\tnn.Dropout(0.5),\n",
    "\t\t\tnn.Linear(2048, 1024),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.BatchNorm1d(1024),\n",
    "\t\t\tnn.Dropout(0.5),\n",
    "\t\t\tnn.Linear(1024, 512),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.BatchNorm1d(512),\n",
    "\t\t\tnn.Linear(512, 2),\n",
    "\t\t)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\treturn self.seq(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PrecomputedClassifier().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=1E-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq.0.weight :    1,179,648\n",
      "seq.0.bias   :          256\n",
      "seq.2.weight :      294,912\n",
      "seq.2.bias   :          128\n",
      "seq.5.weight :   52,428,800\n",
      "seq.5.bias   :        4,096\n",
      "seq.7.weight :        4,096\n",
      "seq.7.bias   :        4,096\n",
      "seq.8.weight :    8,388,608\n",
      "seq.8.bias   :        2,048\n",
      "seq.10.weight:        2,048\n",
      "seq.10.bias  :        2,048\n",
      "seq.12.weight:    2,097,152\n",
      "seq.12.bias  :        1,024\n",
      "seq.14.weight:        1,024\n",
      "seq.14.bias  :        1,024\n",
      "seq.16.weight:      524,288\n",
      "seq.16.bias  :          512\n",
      "seq.18.weight:          512\n",
      "seq.18.bias  :          512\n",
      "seq.19.weight:        1,024\n",
      "seq.19.bias  :            2\n",
      "---------------------------\n",
      "Total:           64,937,858\n"
     ]
    }
   ],
   "source": [
    "s = sum(p.numel() for p in model.parameters())\n",
    "for name, p in model.named_parameters():\n",
    "\tprint(f\"{name: <13}: {p.numel(): >12,}\")\n",
    "\n",
    "print('-' * 27)\n",
    "print(f\"Total: {s: >20,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c87a3c22838e4cabaa57611a27cd4671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/10:   0%|          | 0/510 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aurora/miniconda3/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at /opt/conda/conda-bld/pytorch_1702400440653/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f9f6a5912f2441e81a9be354f3c20a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/10:   0%|          | 0/510 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1246f7c65d124a1ba7c28c23a2cc4b0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/10:   0%|          | 0/510 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "466e7d9f814144fb9167422e3067a2cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/10:   0%|          | 0/510 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ff45514c70a4ba1ad3fce9ac7305697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/10:   0%|          | 0/510 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "967d4e8f64a241688949d1a9609fe549",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/10:   0%|          | 0/510 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f51b84cc6114f50be1f13481f2b8483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/10:   0%|          | 0/510 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "690d47911c1449d085c925366e0e3235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/10:   0%|          | 0/510 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f080d5abcb0d4250b4a72e1c7a00afa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/10:   0%|          | 0/510 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a087a0fa36044b1beb11822562f873b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/10:   0%|          | 0/510 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "epochs = 10\n",
    "history = defaultdict(list)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\tfor i, (inputs, label) in (pbar := tqdm(enumerate(train_loader, 1), total=len(train_loader), desc=f\"Epoch {epoch + 1}/{epochs}\")):\n",
    "\t\toptimizer.zero_grad()\n",
    "\n",
    "\t\tinputs = inputs.to(device)\n",
    "\t\tlabel = label.to(device)\n",
    "\n",
    "\t\toutputs = model(inputs)\n",
    "\t\tloss = criterion(outputs, label)\n",
    "\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\n",
    "\t\thistory[\"loss\"].append(loss.item())\n",
    "\t\tpbar.set_postfix(loss=loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fcd38bb6010>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'vgg16_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('vgg16_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 409 test images: 67.24%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "\tfor inputs, label in test_loader:\n",
    "\t\tinputs = inputs.to(device)\n",
    "\t\tlabel = label.to(device)\n",
    "\t\toutputs = model(inputs)\n",
    "\t\t_, predicted = torch.max(outputs.data, 1)\n",
    "\t\ttotal += label.size(0)\n",
    "\t\tcorrect += (predicted == label).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the {total} test images: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 32640 train images: 99.32%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "\tfor inputs, label in train_loader:\n",
    "\t\tinputs = inputs.to(device)\n",
    "\t\tlabel = label.to(device)\n",
    "\t\toutputs = model(inputs)\n",
    "\t\t_, predicted = torch.max(outputs.data, 1)\n",
    "\t\ttotal += label.size(0)\n",
    "\t\tcorrect += (predicted == label).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the {total} train images: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi model approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "\ttransforms.ToTensor(),\n",
    "\ttransforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_names = ['left_eye', 'right_eye', 'mouth', 'nose']\n",
    "train_datasets = {name: datasets.ImageFolder(f'data_{name}', transform=transform) for name in train_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loaders = {name: DataLoader(train_datasets[name], batch_size=64, shuffle=True) for name in train_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {name: FaceClasifier().to(device) for name in train_names}\n",
    "optimizers = {name: torch.optim.Adam(models[name].parameters(), lr=0.001) for name in train_names}\n",
    "criteria = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64c50fa09e404b1aaf12e869bf31e15f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[left_eye] Epoch 1/1:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45f4f5d2d47344d0945e5ece6c370da5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[right_eye] Epoch 1/1:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d194d6959c6641ee94d17624c44b4a53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[mouth] Epoch 1/1:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74e1bbaaa17241fcb95e4d424fced6ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[nose] Epoch 1/1:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 1\n",
    "from collections import defaultdict\n",
    "\n",
    "train_losses = {name: defaultdict(list) for name in train_names}\n",
    "\n",
    "for feature in train_names:\n",
    "\tmodel = models[feature]\n",
    "\toptimizer = optimizers[feature]\n",
    "\tloader = train_loaders[feature]\n",
    "\thistory = train_losses[feature]\n",
    "\tfor epoch in range(epochs):\n",
    "\t\tfor i, (train, label) in tqdm(enumerate(loader, 1), total=len(loader), desc=f\"[{feature}] Epoch {epoch + 1}/{epochs}\"):\n",
    "\t\t\ttrain = train.to(device)\n",
    "\t\t\tlabel = label.to(device)\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\toutputs = model(train)\n",
    "\t\t\tloss = criteria(outputs, label)\n",
    "\t\t\tloss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\t\t\thistory[\"batch\"].append(i + len(loader) * epoch)\n",
    "\t\t\thistory[\"loss\"].append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(models, 'models.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = torch.load('models.pt')\n",
    "for m in models.values():\n",
    "\tm.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# show a 2 by 2 grid\n",
    "fig, axs = plt.subplots(2, 2, figsize=(15, 15))\n",
    "\n",
    "for i, feature in enumerate(train_names):\n",
    "\taxs[i // 2, i % 2].plot(train_losses[feature][\"batch\"], train_losses[feature][\"loss\"])\n",
    "\taxs[i // 2, i % 2].set_title(feature)\n",
    "\taxs[i // 2, i % 2].set_xlabel(\"batch\")\n",
    "\taxs[i // 2, i % 2].set_ylim(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 600, 600])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = datasets.ImageFolder('data_train', transform=transform)\n",
    "train = DataLoader(train, batch_size=64, shuffle=True)\n",
    "\n",
    "dat, i = next(iter(train))\n",
    "dat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleModel(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(EnsembleModel, self).__init__()\n",
    "\t\tself.fc1 = nn.Linear(8, 32)\n",
    "\t\tself.fc2 = nn.Linear(32, 2)\n",
    "\t\tself.relu = nn.LeakyReLU()\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.relu(self.fc1(x))\n",
    "\t\tx = self.fc2(x)\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemblemodel = EnsembleModel().to(device)\n",
    "optimizer = torch.optim.Adam(params=ensemblemodel.parameters(), lr=0.001)\n",
    "criteria = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b78d2960e5b14345a2b5a4d30245eb2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batches = []\n",
    "for (inputs, label) in tqdm(train, total=len(train)):\n",
    "\twith torch.no_grad():\n",
    "\t\tys = [models[name](inputs) for name in train_names]\n",
    "\t\tz = torch.cat(ys, dim=1)\n",
    "\t\tbatches.append((z, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "\tfor i,(inputs, label) in tqdm(enumerate(batches, 1), total=len(batches), desc=f\"Epoch {epoch + 1}/{epochs}\"):\n",
    "\t\tinputs = inputs.to(device)\n",
    "\t\tlabel = label.to(device)\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\toutput = ensemblemodel(inputs)\n",
    "\t\tloss = criteria(output, label)\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\n",
    "torch.save(ensemblemodel, 'ensemble_model.pt')\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(ensemblemodel, 'ensemble_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnsembleModel(\n",
       "  (fc1): Linear(in_features=8, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=2, bias=True)\n",
       "  (relu): LeakyReLU(negative_slope=0.01)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemblemodel = torch.load('ensemble_model.pt')\n",
    "ensemblemodel.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = datasets.ImageFolder('data_test', transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batches = []\n",
    "for inputs, label in test_loader:\n",
    "\tinputs = inputs.to(device)\n",
    "\tlabel = label.to(device)\n",
    "\twith torch.no_grad():\n",
    "\t\tys = [models[name](inputs) for name in train_names]\n",
    "\t\tz = torch.cat(ys, dim=1)\n",
    "\t\ttest_batches.append((z, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 410 test images: 56.83%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "\n",
    "for inputs, label in test_batches:\n",
    "\twith torch.no_grad():\n",
    "\t\toutput = ensemblemodel(inputs)\n",
    "\t\t_, predicted = torch.max(output.data, 1)\n",
    "\t\tcorrect += (predicted == label).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the {len(test_dataset)} test images: {100 * correct / len(test_dataset):.2f}%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi model using VGG 16"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
